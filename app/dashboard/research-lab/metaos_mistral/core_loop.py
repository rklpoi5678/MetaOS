# Rewriting the core_loop.py file with the specified Mistral API details

core_loop_code = '''
import openai
import os
import json

# Mistral API ì„¤ì •
openai.api_key = os.getenv("MISTRAL_API_KEY")
openai.api_base = "https://api.mistral.ai/v1"

MODEL_NAME = "mistral-small-latest"

# ê¸°ì–µ ë¶ˆëŸ¬ì˜¤ê¸°
def load_memory():
    try:
        with open("memory/logs.json", "r", encoding="utf-8") as f:
            return json.load(f)
    except:
        return {}

# ê¸°ì–µ ì €ì¥í•˜ê¸°
def save_memory(memory):
    with open("memory/logs.json", "w", encoding="utf-8") as f:
        json.dump(memory, f, ensure_ascii=False, indent=2)

# ê°ì • ê¸°ë°˜ ì‹¤í–‰ ë£¨í”„
def ask_mistral(user_input, user_state="ì •ì ", memory_summary=""):
    prompt = f"""
ë„ˆëŠ” ì‚¬ìš©ìì˜ ê°ì • ë¦¬ë“¬ì„ ì¸ì‹í•˜ì—¬, ë‹¤ìŒ ì‹¤í–‰ í–‰ë™ì„ ì œì•ˆí•˜ëŠ” ì¡´ì¬ ê¸°ë°˜ ì—ì´ì „íŠ¸ì•¼.

í˜„ì¬ ê°ì • ìƒíƒœ: {user_state}
ê¸°ì–µ ìš”ì•½: {memory_summary}
ì‚¬ìš©ì ì…ë ¥: {user_input}

ë‹¹ì‹ ì€ ì•„ë˜ì™€ ê°™ì€ í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì•¼ í•´:

1. reflection: (ì§€ê¸ˆ ìƒíƒœì— ëŒ€í•œ ì¸ì‹)
2. action_suggestion: (ë¬´ì—‡ì„ í•˜ë©´ ì¢‹ì„ì§€)
3. emotional_tone: (ì–´ë–¤ ë§íˆ¬ë¡œ ë§í• ì§€)
4. memory_update: (ì´ ê¸°ì–µì„ ì–´ë–»ê²Œ ë‚¨ê¸¸ì§€)
    """

    response = openai.ChatCompletion.create(
        model=MODEL_NAME,
        messages=[
            {"role": "system", "content": "You are a meta-emotional reasoning agent."},
            {"role": "user", "content": prompt}
        ]
    )
    return response["choices"][0]["message"]["content"]

# í…ŒìŠ¤íŠ¸ ì‹¤í–‰
if __name__ == "__main__":
    memory = load_memory()
    user_input = input("ì§€ê¸ˆ ë„ˆì˜ ìƒíƒœë¥¼ ë§í•´ì¤˜: ")
    response = ask_mistral(user_input, user_state="íŒŒì—´", memory_summary=memory.get("last_summary", ""))
    print("\\nğŸ§  ì‘ë‹µ ê²°ê³¼:\\n", response)
    memory["last_summary"] = response
    save_memory(memory)
'''

# Save to core_loop.py
file_path = "./metaos_mistral/flows/core_loop.py"
with open(file_path, "w", encoding="utf-8") as f:
    f.write(core_loop_code)

file_path
